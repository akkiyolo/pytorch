{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBa4o/1ADMyGveU5hSMqno",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akkiyolo/pytorch/blob/main/Tensor_initialization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch tensor initialization :\n",
        "-  torch.zeros()\n",
        "-  torch.ones()\n",
        "-  torch.empty()"
      ],
      "metadata": {
        "id": "x8CgvP08J-u5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_8Z0u6-408sD"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.ones() generates a tensor filled with the value 1.0, configured by the specified shape and optional parameters.\n",
        "\n",
        "Used:\n",
        "\n",
        "* torch.ones() is used to create scaling tensors for element-wise operations, such as normalizing attention scores in transformers.\n",
        "* It's valuable for initializing constant tensors in algorithms like reinforcement learning or custom loss functions.\n",
        "Its predictable values ensure consistency in tasks requiring uniform starting points, like attention masks.\n",
        "\n",
        "- Parameters: size dtype device requires_grad"
      ],
      "metadata": {
        "id": "bgZy7RrLKgLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_tensor=torch.ones(10,5)\n",
        "one_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7KfaAX9Jxhj",
        "outputId": "02459fe1-9c0f-4511-c22a-96bcc4478ee5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_full=torch.ones((3,2),dtype=torch.float16,device='cpu',requires_grad=False)\n",
        "ones_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzAryPLqKj8P",
        "outputId": "6a249c4d-ff47-4905-8290-e25360e0ed83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_full.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmMg93ZPLJk_",
        "outputId": "e879154e-ec9c-4c37-9250-5fad1185bd34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.zeros() creates a tensor filled entirely with the value 0.0, matching the specified shape and data type.\n",
        "\n",
        "Used in:\n",
        "\n",
        "* In deep learning, torch.zeros() is used to initialize biases in neural networks, as zero-initialized biases prevent large initial outputs.\n",
        "* It's also used for creating masks (e.g., zeroing out padded tokens in NLP models) to ensure consistent data processing.\n",
        "\n",
        "- Parameters: size dtype device requires_grad"
      ],
      "metadata": {
        "id": "kUVBB9gALWsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_tensor=torch.zeros(3,3)\n",
        "zero_tensor,zero_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfFJ_SczLwDN",
        "outputId": "64244016-be63-4301-c6f8-55590514bdb4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_full=torch.zeros((3,2),dtype=torch.int32,device='cpu',requires_grad=False) ## requires_grad=True only works for floating point numbers\n",
        "zeros_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuSEVsz7MJjq",
        "outputId": "0283ef40-848b-49c2-c434-4f99dde088f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.empty() creates a tensor filled with uninitialized data. When you use torch.empty(2, 2), PyTorch allocates memory for a 2x2 tensor but does not initialize the values in that memory. Instead, the tensor contains whatever data was already present in that memory location. These values could be leftovers from previous computations, random noise, or even garbage data from the system's memory.\n",
        "\n",
        "* This means that torch.empty() allocates memory for the tensor according to the specified size (shape), but it does not initialize the values within that memory.\n",
        "* The values in the returned tensor will be whatever data was previously present in those memory locations.\n",
        "\n",
        "- When computing millions of gradients (e.g., 2 million) in deep learning, using torch.zeros() or torch.ones() to create a tensor initializes it with specific values, which is inefficient. Instead, torch.empty() allocates a tensor with uninitialized (arbitrary) values, saving time. The computed gradients then overwrite these values, making torch.empty() ideal for temporary buffers like gradient accumulation. This approach avoids unnecessary initialization, improving performance in large-scale training."
      ],
      "metadata": {
        "id": "_5l8OEhTNFkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty_tensor=torch.empty(2,2)\n",
        "empty_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S3FPicJMuoy",
        "outputId": "b357ecd0-cfec-4584-a82f-f27807424413"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.3636e-18,  4.4338e-41],\n",
              "        [ 3.1502e-32,  0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty_tensor.fill_(5.0)\n",
        "empty_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyn5Q1-2NPNX",
        "outputId": "c745e865-a687-486b-e44c-9fa2e5c75a18"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5.],\n",
              "        [5., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty_full=torch.empty((3,3),dtype=torch.float64,device='cpu',requires_grad=False)\n",
        "empty_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxZhfDJiNmVk",
        "outputId": "64105fb2-019a-4e85-94e6-329115c04fcb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.7143e-310, 6.7143e-310, 6.7143e-310],\n",
              "        [6.7143e-310, 6.7143e-310, 6.7143e-310],\n",
              "        [4.7430e-322, 4.7430e-322, 2.2634e-319]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}