{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIggF1dLcF+pVfH6nVYnTH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akkiyolo/pytorch/blob/main/05_gradient_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3HcbMa3f4JS2"
      },
      "outputs": [],
      "source": [
        "## using pytorch for gradient\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "y=torch.tensor([2,4,6,8],dtype=torch.float32)"
      ],
      "metadata": {
        "id": "zlVPXbdT4ZrO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)"
      ],
      "metadata": {
        "id": "O9hV3_KX4uuH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model prediction\n",
        "\n",
        "def forward(x):\n",
        "  return w*x"
      ],
      "metadata": {
        "id": "9R4HcMgY5BrG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss=MSE\n",
        "\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()"
      ],
      "metadata": {
        "id": "v0H_YFIY5CMe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'prediction before training:f(5)={forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HRHFxz45Eed",
        "outputId": "bfa22517-204a-4143-c8e7-55e7e2c095fd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training:f(5)=0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction = forward pass\n",
        "  y_pred=forward(x)\n",
        "\n",
        "  #loss\n",
        "  l=loss(y,y_pred)\n",
        "\n",
        "  #gradients = backward pass\n",
        "  l.backward() #dl/dw\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w-=learning_rate*w.grad\n",
        "\n",
        "  # zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch % 1 ==0:\n",
        "    print(f'epoch {epoch+1}:w={w:.3f},loss={l:.8f}')\n",
        "\n",
        "print(f'prediction after training:f(5)={forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-hcOc2z5HVh",
        "outputId": "9626d47b-5f45-4fb2-a829-16a8110b96a4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1:w=0.300,loss=30.00000000\n",
            "epoch 2:w=0.555,loss=21.67499924\n",
            "epoch 3:w=0.772,loss=15.66018772\n",
            "epoch 4:w=0.956,loss=11.31448650\n",
            "epoch 5:w=1.113,loss=8.17471695\n",
            "epoch 6:w=1.246,loss=5.90623236\n",
            "epoch 7:w=1.359,loss=4.26725292\n",
            "epoch 8:w=1.455,loss=3.08308983\n",
            "epoch 9:w=1.537,loss=2.22753215\n",
            "epoch 10:w=1.606,loss=1.60939169\n",
            "epoch 11:w=1.665,loss=1.16278565\n",
            "epoch 12:w=1.716,loss=0.84011245\n",
            "epoch 13:w=1.758,loss=0.60698116\n",
            "epoch 14:w=1.794,loss=0.43854395\n",
            "epoch 15:w=1.825,loss=0.31684780\n",
            "epoch 16:w=1.851,loss=0.22892261\n",
            "epoch 17:w=1.874,loss=0.16539653\n",
            "epoch 18:w=1.893,loss=0.11949898\n",
            "epoch 19:w=1.909,loss=0.08633806\n",
            "epoch 20:w=1.922,loss=0.06237914\n",
            "epoch 21:w=1.934,loss=0.04506890\n",
            "epoch 22:w=1.944,loss=0.03256231\n",
            "epoch 23:w=1.952,loss=0.02352631\n",
            "epoch 24:w=1.960,loss=0.01699772\n",
            "epoch 25:w=1.966,loss=0.01228084\n",
            "epoch 26:w=1.971,loss=0.00887291\n",
            "epoch 27:w=1.975,loss=0.00641066\n",
            "epoch 28:w=1.979,loss=0.00463169\n",
            "epoch 29:w=1.982,loss=0.00334642\n",
            "epoch 30:w=1.985,loss=0.00241778\n",
            "epoch 31:w=1.987,loss=0.00174685\n",
            "epoch 32:w=1.989,loss=0.00126211\n",
            "epoch 33:w=1.991,loss=0.00091188\n",
            "epoch 34:w=1.992,loss=0.00065882\n",
            "epoch 35:w=1.993,loss=0.00047601\n",
            "epoch 36:w=1.994,loss=0.00034392\n",
            "epoch 37:w=1.995,loss=0.00024848\n",
            "epoch 38:w=1.996,loss=0.00017952\n",
            "epoch 39:w=1.996,loss=0.00012971\n",
            "epoch 40:w=1.997,loss=0.00009371\n",
            "epoch 41:w=1.997,loss=0.00006770\n",
            "epoch 42:w=1.998,loss=0.00004891\n",
            "epoch 43:w=1.998,loss=0.00003534\n",
            "epoch 44:w=1.998,loss=0.00002553\n",
            "epoch 45:w=1.999,loss=0.00001845\n",
            "epoch 46:w=1.999,loss=0.00001333\n",
            "epoch 47:w=1.999,loss=0.00000963\n",
            "epoch 48:w=1.999,loss=0.00000696\n",
            "epoch 49:w=1.999,loss=0.00000503\n",
            "epoch 50:w=1.999,loss=0.00000363\n",
            "epoch 51:w=1.999,loss=0.00000262\n",
            "epoch 52:w=2.000,loss=0.00000190\n",
            "epoch 53:w=2.000,loss=0.00000137\n",
            "epoch 54:w=2.000,loss=0.00000099\n",
            "epoch 55:w=2.000,loss=0.00000071\n",
            "epoch 56:w=2.000,loss=0.00000052\n",
            "epoch 57:w=2.000,loss=0.00000037\n",
            "epoch 58:w=2.000,loss=0.00000027\n",
            "epoch 59:w=2.000,loss=0.00000019\n",
            "epoch 60:w=2.000,loss=0.00000014\n",
            "epoch 61:w=2.000,loss=0.00000010\n",
            "epoch 62:w=2.000,loss=0.00000007\n",
            "epoch 63:w=2.000,loss=0.00000005\n",
            "epoch 64:w=2.000,loss=0.00000004\n",
            "epoch 65:w=2.000,loss=0.00000003\n",
            "epoch 66:w=2.000,loss=0.00000002\n",
            "epoch 67:w=2.000,loss=0.00000001\n",
            "epoch 68:w=2.000,loss=0.00000001\n",
            "epoch 69:w=2.000,loss=0.00000001\n",
            "epoch 70:w=2.000,loss=0.00000001\n",
            "epoch 71:w=2.000,loss=0.00000000\n",
            "epoch 72:w=2.000,loss=0.00000000\n",
            "epoch 73:w=2.000,loss=0.00000000\n",
            "epoch 74:w=2.000,loss=0.00000000\n",
            "epoch 75:w=2.000,loss=0.00000000\n",
            "epoch 76:w=2.000,loss=0.00000000\n",
            "epoch 77:w=2.000,loss=0.00000000\n",
            "epoch 78:w=2.000,loss=0.00000000\n",
            "epoch 79:w=2.000,loss=0.00000000\n",
            "epoch 80:w=2.000,loss=0.00000000\n",
            "epoch 81:w=2.000,loss=0.00000000\n",
            "epoch 82:w=2.000,loss=0.00000000\n",
            "epoch 83:w=2.000,loss=0.00000000\n",
            "epoch 84:w=2.000,loss=0.00000000\n",
            "epoch 85:w=2.000,loss=0.00000000\n",
            "epoch 86:w=2.000,loss=0.00000000\n",
            "epoch 87:w=2.000,loss=0.00000000\n",
            "epoch 88:w=2.000,loss=0.00000000\n",
            "epoch 89:w=2.000,loss=0.00000000\n",
            "epoch 90:w=2.000,loss=0.00000000\n",
            "epoch 91:w=2.000,loss=0.00000000\n",
            "epoch 92:w=2.000,loss=0.00000000\n",
            "epoch 93:w=2.000,loss=0.00000000\n",
            "epoch 94:w=2.000,loss=0.00000000\n",
            "epoch 95:w=2.000,loss=0.00000000\n",
            "epoch 96:w=2.000,loss=0.00000000\n",
            "epoch 97:w=2.000,loss=0.00000000\n",
            "epoch 98:w=2.000,loss=0.00000000\n",
            "epoch 99:w=2.000,loss=0.00000000\n",
            "epoch 100:w=2.000,loss=0.00000000\n",
            "prediction after training:f(5)=10.000\n"
          ]
        }
      ]
    }
  ]
}